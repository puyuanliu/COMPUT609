20000 runs policy gradient

tilings 32

actor_range: 2^-6, 2^1
critic_step_size_range: 2**-4, 2**2

avg_reward_step_size: 2^-8

actor_range: [0.016, 0.299, 0.583, 0.866, 1.15, 1.433, 1.717, 2.0]
critic_step_size_range:  [0.062, 0.625, 1.188, 1.75, 2.312, 2.875, 3.438, 4.0]

exponential reward: 

[-1.894 -0.813 -0.929 -1.    -1.008 -1.227 -2.613 -2.764;
 -1.987 -0.022 -0.066 -0.268 -0.585 -0.811 -2.735 -2.705;
 -1.931 -0.173 -0.423 -0.813 -0.801 -1.324 -2.623 -2.771;
 -2.281 -0.535 -0.662 -0.85  -1.11  -1.828 -2.621 -2.607;
 -2.229 -0.595 -0.662 -0.92  -1.101 -1.673 -2.652 -2.785;
 -2.269 -0.909 -0.763 -1.171 -1.272 -1.66  -2.699 -2.725;
 -2.351 -0.762 -0.862 -1.151 -1.402 -2.144 -2.769 -2.738;
 -2.406 -1.281 -1.651 -2.009 -1.959 -2.406 -2.812 -2.782]

20000 runs policy gradient

tilings 32

actor_range: 2^-6, 2^1
critic_step_size_range: 2**-4, 2**2

avg_reward_step_size: 2^-7

actor_range: [0.016, 0.299, 0.583, 0.866, 1.15, 1.433, 1.717, 2.0]
critic_step_size_range:  [0.062, 0.625, 1.188, 1.75, 2.312, 2.875, 3.438, 4.0]

exponential reward: 
[-2.074 -1.074 -1.038 -1.037 -1.069 -1.14  -2.664 -2.732;
 -2.118 -0.017 -0.029 -0.079 -0.04  -0.343 -2.35  -2.747;
 -2.262 -0.179 -0.139 -0.136 -0.205 -0.724 -2.157 -2.618;
 -2.286 -0.438 -0.589 -0.369 -0.454 -0.939 -2.559 -2.797;
 -2.348 -0.564 -0.376 -0.491 -0.515 -1.222 -2.694 -2.873;
 -2.336 -0.814 -0.668 -0.681 -0.429 -1.547 -2.499 -2.783;
 -2.284 -0.897 -0.717 -0.903 -0.945 -1.888 -2.672 -2.736;
 -2.492 -1.274 -1.28  -1.502 -1.638 -2.253 -2.608 -2.959]



20000 runs policy gradient

tilings 32

actor_range: 2^-6, 2^1
critic_step_size_range: 2**-4, 2**2

avg_reward_step_size: 2^-6

actor_range: [0.016, 0.299, 0.583, 0.866, 1.15, 1.433, 1.717, 2.0]
critic_step_size_range:  [0.062, 0.625, 1.188, 1.75, 2.312, 2.875, 3.438, 4.0]

exponential reward: 
[-2.144 -1.245 -1.163 -1.131 -1.142 -1.217 -2.545 -2.688;
 -2.337 -0.049 -0.015 -0.014 -0.014 -0.164 -1.954 -2.62 ;
 -2.368 -0.087 -0.079 -0.023 -0.097 -0.276 -2.094 -2.706;
 -2.453 -0.397 -0.158 -0.351 -0.25  -0.468 -2.364 -2.771;
 -2.361 -0.464 -0.246 -0.276 -0.428 -0.815 -2.359 -2.489;
 -2.426 -0.659 -0.306 -0.376 -0.438 -0.909 -2.345 -2.68 ;
 -2.538 -1.108 -0.581 -0.475 -0.632 -1.029 -2.471 -2.752;
 -2.5   -1.499 -1.098 -1.032 -1.304 -1.996 -2.697 -2.868]


20000 runs policy gradient

tilings 32

actor_range: 2^-6, 2^1
critic_step_size_range: 2**-4, 2**2

avg_reward_step_size: 2^-5

actor_range: [0.016, 0.299, 0.583, 0.866, 1.15, 1.433, 1.717, 2.0]
critic_step_size_range:  [0.062, 0.625, 1.188, 1.75, 2.312, 2.875, 3.438, 4.0]

exponential reward: 

[-2.108 -1.387 -1.298 -1.27  -1.25  -1.262 -2.461 -2.709;
 -2.371 -0.39  -0.034 -0.016 -0.04  -0.241 -1.66  -2.515;
 -2.273 -0.68  -0.121 -0.014 -0.053 -0.313 -1.649 -2.672;
 -2.293 -0.791 -0.21  -0.172 -0.22  -0.182 -1.72  -2.62 ;
 -2.398 -0.876 -0.233 -0.186 -0.25  -0.595 -1.724 -2.691;
 -2.471 -1.035 -0.353 -0.457 -0.524 -0.797 -1.95  -2.6  ;
 -2.439 -0.996 -0.253 -0.239 -0.45  -1.151 -1.976 -2.759;
 -2.463 -1.286 -1.017 -0.731 -0.972 -1.538 -2.571 -2.768]


20000 runs policy gradient

tilings 64

actor_range: 2^-6, 2^1
critic_step_size_range: 2**-4, 2**2

avg_reward_step_size: 2^-8

actor_range: [0.016, 0.299, 0.583, 0.866, 1.15, 1.433, 1.717, 2.0]
critic_step_size_range:  [0.062, 0.625, 1.188, 1.75, 2.312, 2.875, 3.438, 4.0]

exponential reward: 

[-1.901 -0.845 -0.827 -0.911 -0.991 -1.049 -2.496 -2.798;
 -1.918 -0.103 -0.086 -0.238 -0.452 -1.051 -2.18  -2.662;
 -2.037 -0.15  -0.299 -0.319 -0.593 -0.88  -2.353 -2.812;
 -2.126 -0.568 -0.503 -0.58  -0.928 -1.259 -2.544 -2.647;
 -2.257 -0.517 -0.666 -0.769 -0.914 -1.359 -2.465 -2.8  ;
 -2.234 -0.671 -0.489 -0.828 -1.048 -1.376 -2.409 -2.784;
 -2.288 -1.033 -0.656 -0.845 -1.372 -1.991 -2.667 -2.713;
 -2.504 -1.1   -1.275 -1.17  -1.338 -2.164 -2.774 -2.69 ]


20000 runs policy gradient

tilings 64

actor_range: 2^-6, 2^1
critic_step_size_range: 2**-4, 2**2

avg_reward_step_size: 2^-7

actor_range: [0.016, 0.299, 0.583, 0.866, 1.15, 1.433, 1.717, 2.0]
critic_step_size_range:  [0.062, 0.625, 1.188, 1.75, 2.312, 2.875, 3.438, 4.0]

exponential reward: 

[-2.07  -1.045 -0.958 -1.002 -1.022 -1.084 -2.585 -2.747;
 -2.093 -0.027 -0.016 -0.058 -0.04  -0.341 -2.016 -2.664;
 -2.285 -0.053 -0.06  -0.177 -0.278 -0.525 -2.168 -2.636;
 -2.258 -0.236 -0.257 -0.231 -0.327 -0.643 -2.366 -2.542;
 -2.339 -0.609 -0.312 -0.347 -0.469 -0.676 -2.097 -2.786;
 -2.36  -0.555 -0.436 -0.318 -0.411 -0.662 -2.336 -2.627;
 -2.442 -0.483 -0.397 -0.54  -0.843 -1.809 -2.539 -2.641;
 -2.359 -0.911 -0.629 -0.993 -1.29  -1.76  -2.526 -2.77 ]

20000 runs policy gradient

tilings 64

actor_range: 2^-6, 2^1
critic_step_size_range: 2**-4, 2**2

avg_reward_step_size: 2^-6

actor_range: [0.016, 0.299, 0.583, 0.866, 1.15, 1.433, 1.717, 2.0]
critic_step_size_range:  [0.062, 0.625, 1.188, 1.75, 2.312, 2.875, 3.438, 4.0]

exponential reward: 

[-2.126 -1.252 -1.176 -1.119 -1.122 -1.144 -2.415 -2.696;
 -2.326 -0.052 -0.013 -0.014 -0.012 -0.013 -1.449 -2.572;
 -2.381 -0.046 -0.012 -0.019 -0.07  -0.175 -1.349 -2.624;
 -2.375 -0.438 -0.141 -0.306 -0.301 -0.256 -1.772 -2.511;
 -2.4   -0.637 -0.111 -0.226 -0.209 -0.524 -1.746 -2.576;
 -2.444 -0.591 -0.279 -0.339 -0.074 -0.601 -1.718 -2.624;
 -2.401 -0.764 -0.286 -0.482 -0.565 -0.548 -1.9   -2.483;
 -2.444 -0.882 -0.576 -0.631 -1.102 -1.353 -2.356 -2.671]

20000 runs policy gradient

tilings 64

actor_range: 2^-6, 2^1
critic_step_size_range: 2**-4, 2**2

avg_reward_step_size: 2^-5

actor_range: [0.016, 0.299, 0.583, 0.866, 1.15, 1.433, 1.717, 2.0]
critic_step_size_range:  [0.062, 0.625, 1.188, 1.75, 2.312, 2.875, 3.438, 4.0]

exponential reward: 

[-2.198 -1.439 -1.279 -1.261 -1.222 -1.33  -2.477 -2.617;
 -2.344 -0.188 -0.017 -0.014 -0.013 -0.07  -1.763 -2.621;
 -2.381 -0.735 -0.057 -0.012 -0.027 -0.178 -1.208 -2.609;
 -2.387 -0.743 -0.117 -0.14  -0.115 -0.178 -1.406 -2.385;
 -2.424 -0.731 -0.211 -0.146 -0.198 -0.325 -1.425 -2.369;
 -2.501 -0.929 -0.225 -0.08  -0.258 -0.356 -1.53  -2.602;
 -2.294 -0.948 -0.317 -0.209 -0.248 -0.687 -1.697 -2.574;
 -2.428 -0.94  -0.57  -0.259 -0.594 -0.909 -2.05  -2.619]



20000 runs policy gradient

tilings 64

actor_range: 2^-6, 2^1
critic_step_size_range: 2**-4, 2**2

avg_reward_step_size: 2^-8

actor_range: [0.016, 0.299, 0.583, 0.866, 1.15, 1.433, 1.717, 2.0]
critic_step_size_range:  [0.062, 0.625, 1.188, 1.75, 2.312, 2.875, 3.438, 4.0]

exponential reward: 





20000 runs policy gradient

tilings 64

actor_range: 2^-6, 2^1
critic_step_size_range: 2**-4, 2**2

avg_reward_step_size: 2^-7

actor_range: [0.016, 0.299, 0.583, 0.866, 1.15, 1.433, 1.717, 2.0]
critic_step_size_range:  [0.062, 0.625, 1.188, 1.75, 2.312, 2.875, 3.438, 4.0]

exponential reward: 




20000 runs policy gradient

tilings 64

actor_range: 2^-6, 2^1
critic_step_size_range: 2**-4, 2**2

avg_reward_step_size: 2^-6

actor_range: [0.016, 0.299, 0.583, 0.866, 1.15, 1.433, 1.717, 2.0]
critic_step_size_range:  [0.062, 0.625, 1.188, 1.75, 2.312, 2.875, 3.438, 4.0]

exponential reward: 

[-2.123 -1.235 -1.161 -1.129 -1.14  -1.143 -2.453 -2.547;
 -2.309 -0.051 -0.015 -0.013 -0.012 -0.063 -1.704 -2.57 ;
 -2.213 -0.201 -0.015 -0.022 -0.018 -0.28  -1.413 -2.498;
 -2.229 -0.372 -0.232 -0.278 -0.17  -0.395 -1.604 -2.53 ;
 -2.369 -0.371 -0.21  -0.163 -0.215 -0.39  -1.882 -2.74;
 -2.496 -0.538 -0.224 -0.198 -0.31  -0.444 -2.014 -2.614;
 -2.583 -0.705 -0.506 -0.592 -1.084 -1.264 -2.119 -2.77 ;
 -2.59  -1.093 -0.872 -0.985 -1.539 -1.717 -2.437 -2.736]


20000 runs policy gradient

tilings 64

actor_range: 2^-6, 2^1
critic_step_size_range: 2**-4, 2**2

avg_reward_step_size: 2^-5

actor_range: [0.016, 0.299, 0.583, 0.866, 1.15, 1.433, 1.717, 2.0]
critic_step_size_range:  [0.062, 0.625, 1.188, 1.75, 2.312, 2.875, 3.438, 4.0]

exponential reward: 

[-2.161 -1.43  -1.29  -1.236 -1.232 -1.279 -2.371 -2.645;
 -2.344 -0.309 -0.02  -0.038 -0.013 -0.1   -1.408 -2.685;
 -2.307 -0.47  -0.063 -0.013 -0.011 -0.14  -0.926 -2.584;
 -2.403 -0.792 -0.252 -0.227 -0.031 -0.419 -1.602 -2.601;
 -2.407 -0.729 -0.347 -0.015 -0.156 -0.315 -1.446 -2.732;
 -2.415 -1.085 -0.281 -0.2   -0.083 -0.516 -1.555 -2.499;
 -2.314 -1.163 -0.577 -0.609 -0.694 -1.025 -1.855 -2.675;
 -2.361 -1.574 -0.873 -0.911 -0.707 -1.159 -1.941 -2.675]


